{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Action Discriptions and Dialogue from Movie Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we extract all action descriptions and dialogue contained in movie scripts from `scriptbase_alpha` https://github.com/EdinburghNLP/scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools, re\n",
    "from collections import Counter\n",
    "import gender_guesser.detector as gender\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import spacy \n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Script Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this requires the scriptbase_j repository: https://github.com/EdinburghNLP/scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_fns = files = glob.glob('/home/fhopp/projects/templeton/sony/scriptbase/scriptbase_j/*/processed/script_clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movie scripts: 917\n"
     ]
    }
   ],
   "source": [
    "print('Total number of movie scripts:', len(script_fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataformat will be a dataframe that is indexed by each movie title and contains all the dialogue and all the action descriptions.\n",
    "\n",
    "Action descriptions and dialogues will be detected via their different indentation levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_fns = glob.glob('/home/fhopp/projects/templeton/sony/scriptbase/scriptbase_j/*/processed/script.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we extract the dialogue and all action descriptions from each movie. This may take up to 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for script in script_fns:\n",
    "    title = script.split('/')[-3].split('(')[0].strip()\n",
    "    df = pd.DataFrame(index = [title], columns =['dialogue','action'])\n",
    "    \n",
    "    xml = minidom.parse(script)\n",
    "    \n",
    "    \n",
    "    # Dialogues\n",
    "    dialogue_objects = []\n",
    "    dialogue = xml.getElementsByTagName('speech')\n",
    "    words_in_dialogue = []\n",
    "\n",
    "    for s in dialogue:\n",
    "        sentence = s.getElementsByTagName('sentence')\n",
    "        word_list = [w.getElementsByTagName('word') for w in sentence]\n",
    "        # loop through the XML word objects and get the actual word \n",
    "        for w in word_list:\n",
    "            for x in w:\n",
    "                if x.firstChild.data != list():\n",
    "                    words_in_dialogue.append(x.firstChild.data)\n",
    "\n",
    "\n",
    "    # Clean Dialogue\n",
    "    joined_words = ' '.join(words_in_dialogue)\n",
    "    joined_words = joined_words.replace(\" ?\",\"?\")\n",
    "    joined_words = joined_words.replace(\" .\",\".\")\n",
    "    joined_words = joined_words.replace(\" !\",\"!\")\n",
    "    joined_words = joined_words.replace(\" '\",\"'\")\n",
    "    joined_words = joined_words.replace(\" ,\",\",\")\n",
    "    joined_words = joined_words.replace(\" ;\",\";\")\n",
    "    joined_words = joined_words.replace(\" - \",\"-\")\n",
    "    joined_words = joined_words.replace(\"- \",\"-\")\n",
    "    joined_words = joined_words.replace(\" na\",\"na\")\n",
    "    joined_words = joined_words.replace(\" n't\",\"n't\")\n",
    "    clean_dialogue = joined_words\n",
    "    df['dialogue'] = clean_dialogue\n",
    "\n",
    "    # Action Descriptions\n",
    "    action_objects = []\n",
    "    action = xml.getElementsByTagName('description')\n",
    "    words_in_action = []\n",
    "\n",
    "    for s in action:\n",
    "        sentence = s.getElementsByTagName('sentence')\n",
    "        word_list = [w.getElementsByTagName('word') for w in sentence]\n",
    "        # loop through the XML word objects and get the actual word \n",
    "        for w in word_list:\n",
    "            for x in w:\n",
    "                if x.firstChild.data != list():\n",
    "                    words_in_action.append(x.firstChild.data)\n",
    "\n",
    "\n",
    "    # Clean Actions\n",
    "    joined_words = ' '.join(words_in_action)\n",
    "    joined_words = joined_words.replace(\" .\",\".\")\n",
    "    joined_words = joined_words.replace(\" !\",\"!\")\n",
    "    joined_words = joined_words.replace(\" '\",\"'\")\n",
    "    joined_words = joined_words.replace(\" ,\",\",\")\n",
    "    joined_words = joined_words.replace(\" ;\",\";\")\n",
    "    joined_words = joined_words.replace(\" - \",\"-\")\n",
    "    joined_words = joined_words.replace(\" n't\",\"n't\")\n",
    "    clean_action = joined_words\n",
    "    df['action'] = clean_action\n",
    "    \n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.to_csv('scripts4scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.to_pickle('scripts4scoring.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
