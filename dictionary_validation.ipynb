{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Document Scoring, Application, and External Validation of E-MFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import re, fnmatch \n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "punctuation += '’'\n",
    "for i in range(0,10):\n",
    "    punctuation += str(i)\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundations = ['care','fairness','loyalty','authority','sanctity']\n",
    "# neutrals = [f+'.neutral' for f in foundations]\n",
    "# foundations = virtues+vices+neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load News Articles\n",
    "news_text = pd.read_json('../datasets/uncoded_news.json').set_index('url')\n",
    "news = pd.read_pickle('data/study1_news.pkl').set_index('url')\n",
    "news = news.join(news_text['text'])\n",
    "themes = [c for c in news.columns if c.isupper()] \n",
    "news = news[['text','share_count']+themes]\n",
    "stopwords = set(list(nltk_stopwords) + list(ENGLISH_STOP_WORDS) + list(STOP_WORDS))\n",
    "news = news.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>share_count</th>\n",
       "      <th>ACT_HARMTHREATEN</th>\n",
       "      <th>AFFECT</th>\n",
       "      <th>ARMEDCONFLICT</th>\n",
       "      <th>CYBER_ATTACK</th>\n",
       "      <th>EXHUMATION</th>\n",
       "      <th>EXTREMISM</th>\n",
       "      <th>FREESPEECH</th>\n",
       "      <th>JIHAD</th>\n",
       "      <th>KILL</th>\n",
       "      <th>LEGISLATION</th>\n",
       "      <th>MOVEMENT_SOCIAL</th>\n",
       "      <th>PROTEST</th>\n",
       "      <th>REBELLION</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>TERROR</th>\n",
       "      <th>WOUND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mobile.reuters.com/article/worldNews/id...</td>\n",
       "      <td>The Iraqi government's assault to retake the c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.cbsnews.com/news/north-korea-can-la...</td>\n",
       "      <td>WASHINGTON -- North Korea now has the capabili...</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.breitbart.com/national-security/201...</td>\n",
       "      <td>TEL AVIV – An Egyptian journalist wrote an op-...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.cnn.com/2016/12/07/europe/russia-re...</td>\n",
       "      <td>What was life like for Russians such as Tsar N...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.foxnews.com/politics/2016/12/05/for...</td>\n",
       "      <td>President Obama's former national security adv...</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://mobile.reuters.com/article/worldNews/id...   \n",
       "1  http://www.cbsnews.com/news/north-korea-can-la...   \n",
       "2  http://www.breitbart.com/national-security/201...   \n",
       "3  http://www.cnn.com/2016/12/07/europe/russia-re...   \n",
       "4  http://www.foxnews.com/politics/2016/12/05/for...   \n",
       "\n",
       "                                                text  share_count  \\\n",
       "0  The Iraqi government's assault to retake the c...          0.0   \n",
       "1  WASHINGTON -- North Korea now has the capabili...        262.0   \n",
       "2  TEL AVIV – An Egyptian journalist wrote an op-...         41.0   \n",
       "3  What was life like for Russians such as Tsar N...        114.0   \n",
       "4  President Obama's former national security adv...        244.0   \n",
       "\n",
       "   ACT_HARMTHREATEN  AFFECT  ARMEDCONFLICT  CYBER_ATTACK  EXHUMATION  \\\n",
       "0                 0       1              1             0           0   \n",
       "1                 0       0              0             0           0   \n",
       "2                 0       0              1             0           0   \n",
       "3                 0       0              0             0           0   \n",
       "4                 0       0              1             0           0   \n",
       "\n",
       "   EXTREMISM  FREESPEECH  JIHAD  KILL  LEGISLATION  MOVEMENT_SOCIAL  PROTEST  \\\n",
       "0          0           0      0     0            0                0        0   \n",
       "1          0           0      0     0            0                0        1   \n",
       "2          1           0      0     1            0                0        0   \n",
       "3          0           0      0     1            0                0        0   \n",
       "4          0           0      0     0            1                0        1   \n",
       "\n",
       "   REBELLION  RELIGION  TERROR  WOUND  \n",
       "0          0         0       1      1  \n",
       "1          0         0       0      0  \n",
       "2          0         0       0      0  \n",
       "3          0         0       0      0  \n",
       "4          1         0       0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess sentences\n",
    "def preproc_sent(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "    sentence = [x.replace(\"'s\",'') for x in sentence]\n",
    "    for punc in punctuation:\n",
    "        sentence = [x.replace(punc,'') for x in sentence]\n",
    "    sentence = [x for x in sentence if x not in stopwords]\n",
    "    sentence = [x for x in sentence if x not in punctuation]\n",
    "    sentence = [x for x in sentence if len(x) > 2]\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Score Documents with E-MFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score E-MFD\n",
    "emfd = pd.read_pickle('dictionaries/emfd_scoring.pkl')[['care_norm','fairness_norm','authority_norm','loyalty_norm','sanctity_norm', 'var']]\n",
    "emfd = emfd.rename(columns={'care_norm':'care','fairness_norm':'fairness', 'authority_norm':'authority', 'loyalty_norm':'loyalty','sanctity_norm':'sanctity'})\n",
    "emfd = emfd.iloc[pd.np.where(emfd[['care', 'fairness', 'loyalty','authority','sanctity']].ge(0.1).any(1, skipna=True))]\n",
    "emfd = emfd.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3309"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_rw = []\n",
    "\n",
    "for i, row in news.iterrows():  \n",
    "    doc_id = i\n",
    "    #print('This is document:', doc_id)\n",
    "    \n",
    "    # Turn document into spaCy DOC object\n",
    "    doc = nlp(row.text)\n",
    "    \n",
    "    # Create list to store individual sentence scores\n",
    "    sentence_scores = []\n",
    "    \n",
    "    # Initialize a variable to store the number of detected moral words \n",
    "    emfd_wordcount = 0 \n",
    "    non_moral_count = 0\n",
    "    \n",
    "    # Start to loop over each sentence in a document\n",
    "    for s, sentence in enumerate(doc.sents):\n",
    "        \n",
    "        # Run VADER to get sentence sentiment\n",
    "        sentiment = analyzer.polarity_scores(str(sentence))\n",
    "        \n",
    "        # Preprocess sentence and turn into list of tokens \n",
    "        tokens = preproc_sent(str(sentence).strip())\n",
    "        \n",
    "        # If an empty sentence is returned, skip this sentence\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "#         print(tokens)\n",
    "        emfd_score = pd.DataFrame(columns=foundations, index=range(0, len(tokens)))\n",
    "        emfd_score['pos'] = sentiment['pos']\n",
    "        emfd_score['neg'] = sentiment['neg']\n",
    "        emfd_score['neu'] = sentiment['neu']\n",
    "        emfd_score['pol'] = sentiment['compound']\n",
    "        emfd_score['word'] = ''\n",
    "                \n",
    "        # Initiate scoring by looping over each token in the sentence\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in E-MFD?\n",
    "            if token in emfd.keys():\n",
    "                # Yes: increase wordcount by 1\n",
    "                emfd_wordcount += 1\n",
    "                # In scoring matrix, insert words and insert weights \n",
    "                emfd_score.at[x, 'word'] = token\n",
    "                emfd_score.at[x,'care'] = emfd[token]['care']\n",
    "                emfd_score.at[x,'fairness'] = emfd[token]['fairness']\n",
    "                emfd_score.at[x,'loyalty'] = emfd[token]['loyalty']\n",
    "                emfd_score.at[x,'authority'] = emfd[token]['authority']\n",
    "                emfd_score.at[x,'sanctity'] = emfd[token]['sanctity']\n",
    "            else:\n",
    "                non_moral_count += 1\n",
    "                # If word not in EMFD, add word and add 0 weights \n",
    "                emfd_score.at[x, 'word'] = token\n",
    "                emfd_score.at[x,'care'] = 0.0\n",
    "                emfd_score.at[x,'fairness'] = 0.0\n",
    "                emfd_score.at[x,'loyalty'] = 0.0\n",
    "                emfd_score.at[x,'authority'] = 0.0\n",
    "                emfd_score.at[x,'sanctity'] = 0.0\n",
    "                \n",
    "        emfd_score['word_ix'] = emfd_score.index\n",
    "        emfd_score['sentence_ix'] = int(s)\n",
    "        emfd_score['document_ix'] = int(i)\n",
    "        emfd_score['shares'] = row['share_count']\n",
    "        #print(emfd_score)\n",
    "        sentence_scores.append(emfd_score)\n",
    "        \n",
    "    # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "    sentences = pd.concat(sentence_scores)\n",
    "    sentences['moral_nonmoral_ratio'] = emfd_wordcount / non_moral_count\n",
    "    #print(\"this is a document\")\n",
    "    #print(sentences)\n",
    "    docs_rw.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care','fairness','loyalty','authority','sanctity','moral_nonmoral_ratio','pos','neg','neu','pol','shares','word']]\n",
    "df.to_csv('emfd_docs4rw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_ix</th>\n",
       "      <th>sentence_ix</th>\n",
       "      <th>word_ix</th>\n",
       "      <th>care</th>\n",
       "      <th>fairness</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>authority</th>\n",
       "      <th>sanctity</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pol</th>\n",
       "      <th>shares</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>iraqi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14994</td>\n",
       "      <td>0.181717</td>\n",
       "      <td>0.170055</td>\n",
       "      <td>0.223723</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>0.0702811</td>\n",
       "      <td>0.102415</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.0719794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_ix  sentence_ix  word_ix      care   fairness   loyalty authority  \\\n",
       "0            0            0        0         0          0         0         0   \n",
       "1            0            0        1   0.14994   0.181717  0.170055  0.223723   \n",
       "2            0            0        2  0.385417   0.189474  0.214286  0.182927   \n",
       "3            0            0        3  0.172414          0       0.2  0.368421   \n",
       "4            0            0        4  0.118093  0.0702811  0.102415  0.130682   \n",
       "\n",
       "    sanctity  pos    neg    neu     pol  shares        word  \n",
       "0          0  0.0  0.203  0.797 -0.8555     0.0       iraqi  \n",
       "1   0.111842  0.0  0.203  0.797 -0.8555     0.0  government  \n",
       "2   0.233333  0.0  0.203  0.797 -0.8555     0.0     assault  \n",
       "3     0.1875  0.0  0.203  0.797 -0.8555     0.0      retake  \n",
       "4  0.0719794  0.0  0.203  0.797 -0.8555     0.0        city  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Score Documents with MFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate MFD\n",
    "MFD = 'dictionaries/mft_original.dic'\n",
    "nummap = dict()\n",
    "mfd = dict()\n",
    "mfd_regex = dict()\n",
    "wordmode = True\n",
    "with open(MFD, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                mfd[ent[0]] = [nummap[e] for e in ent[1:]]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "# convert vocab to compiled regex for comparison\n",
    "for v in mfd.keys():\n",
    "    mfd_regex[v] = re.compile(fnmatch.translate(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate MFD2.0 \n",
    "MFD2 = 'dictionaries/mfd2.0.dic'\n",
    "nummap = dict()\n",
    "mfd2 = dict()\n",
    "wordmode = True\n",
    "with open(MFD2, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                wordkey = ''.join([e for e in ent if e not in nummap.keys()])\n",
    "                mfd2[wordkey] = [nummap[e] for e in ent if e in nummap.keys()]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "mfd2 = pd.DataFrame.from_dict(mfd2).T\n",
    "mfd2['foundation'] = mfd2[0]\n",
    "del mfd2[0]\n",
    "mfd2 = mfd2.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtues = [f+'.virtue' for f in foundations]\n",
    "vices = [f+'.vice' for f in foundations]\n",
    "mfd_foundations = virtues+vices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score MFD \n",
    "docs_rw = []\n",
    "\n",
    "for i, row in news.iterrows():  \n",
    "    doc_id = i\n",
    "    \n",
    "    # Turn document into spaCy DOC object\n",
    "    doc = nlp(row.text)\n",
    "    \n",
    "    # Create list to store individual sentence scores\n",
    "    sentence_scores = []\n",
    "    \n",
    "    # Initialize a variable to store the number of detected moral words \n",
    "    mfd_wordcount = 0 \n",
    "    non_mfd_count = 0\n",
    "    \n",
    "    # Start to loop over each sentence in a document\n",
    "    for s, sentence in enumerate(doc.sents):\n",
    "        \n",
    "        # Run VADER to get sentence sentiment\n",
    "        sentiment = analyzer.polarity_scores(str(sentence))\n",
    "        \n",
    "        # Preprocess sentence and turn into list of tokens \n",
    "        tokens = preproc_sent(str(sentence).strip())\n",
    "        \n",
    "        # If an empty sentence is returned, skip this sentence\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "        #print(tokens)\n",
    "        mfd_score = pd.DataFrame(columns=mfd_foundations, index=range(0, len(tokens)))\n",
    "        mfd_score['word'] = ''\n",
    "        mfd_score = mfd_score.fillna(0)\n",
    "                \n",
    "        # Initiate scoring by looping over each token in the sentence\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in MFD?\n",
    "            for v in mfd_regex.keys():\n",
    "                if mfd_regex[v].match(token):\n",
    "                    mfd_wordcount += 1\n",
    "                    for f in mfd[v]:\n",
    "                        if f == 'moral':\n",
    "                            continue\n",
    "                        else:\n",
    "                            #print(token,f)\n",
    "                            mfd_score.at[x,'word'] = token\n",
    "                            mfd_score.at[x,f] = 1\n",
    "                else:\n",
    "                    non_mfd_count += 1\n",
    "                    mfd_score.at[x,'word'] = token\n",
    "                    continue\n",
    "        \n",
    "        mfd_score['word_ix'] = mfd_score.index\n",
    "        mfd_score['sentence_ix'] = int(s)\n",
    "        mfd_score['document_ix'] = int(i)\n",
    "        mfd_score['shares'] = row['share_count']\n",
    "        sentence_scores.append(mfd_score)\n",
    "        \n",
    "    # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "    sentences = pd.concat(sentence_scores)\n",
    "    sentences['moral_nonmoral_ratio'] = mfd_wordcount / non_mfd_count\n",
    "    #print(\"this is a document\")\n",
    "    #print(sentences)\n",
    "    docs_rw.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save scored MFD counts\n",
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care.virtue', 'fairness.virtue' ,'loyalty.virtue', 'authority.virtue' ,'sanctity.virtue' ,'care.vice' ,'fairness.vice' ,'loyalty.vice' ,'authority.vice', 'sanctity.vice', 'moral_nonmoral_ratio','shares','word']]\n",
    "df.to_csv('mfd_docs4rw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score MFD2.0 \n",
    "docs_rw = []\n",
    "\n",
    "for i, row in news.iterrows():  \n",
    "    doc_id = i\n",
    "    \n",
    "    # Turn document into spaCy DOC object\n",
    "    doc = nlp(row.text)\n",
    "    \n",
    "    # Create list to store individual sentence scores\n",
    "    sentence_scores = []\n",
    "    \n",
    "    # Initialize a variable to store the number of detected moral words \n",
    "    mfd_wordcount = 0 \n",
    "    non_mfd_count = 0\n",
    "    \n",
    "    # Start to loop over each sentence in a document\n",
    "    for s, sentence in enumerate(doc.sents):\n",
    "        \n",
    "        # Run VADER to get sentence sentiment\n",
    "        sentiment = analyzer.polarity_scores(str(sentence))\n",
    "        \n",
    "        # Preprocess sentence and turn into list of tokens \n",
    "        tokens = preproc_sent(str(sentence).strip())\n",
    "        \n",
    "        # If an empty sentence is returned, skip this sentence\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "        #print(tokens)\n",
    "        mfd_score = pd.DataFrame(columns=mfd_foundations, index=range(0, len(tokens)))\n",
    "        mfd_score['word'] = ''\n",
    "        mfd_score = mfd_score.fillna(0)\n",
    "                \n",
    "        # Initiate scoring by looping over each token in the sentence\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in MFD2?\n",
    "            if token in mfd2.keys(): \n",
    "                mfd_wordcount += 1\n",
    "                mfd_score.at[x,'word'] = token\n",
    "                mfd_score.at[x, mfd2[token]['foundation']] = 1\n",
    "                               \n",
    "            else:\n",
    "                non_mfd_count += 1\n",
    "                mfd_score.at[x,'word'] = token\n",
    "                continue\n",
    "        \n",
    "        mfd_score['word_ix'] = mfd_score.index\n",
    "        mfd_score['sentence_ix'] = int(s)\n",
    "        mfd_score['document_ix'] = int(i)\n",
    "        mfd_score['shares'] = row['share_count']\n",
    "        sentence_scores.append(mfd_score)\n",
    "        \n",
    "    # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "    sentences = pd.concat(sentence_scores)\n",
    "    sentences['moral_nonmoral_ratio'] = mfd_wordcount / non_mfd_count\n",
    "    #print(\"this is a document\")\n",
    "    #print(sentences)\n",
    "    docs_rw.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save scored MFD counts\n",
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care.virtue', 'fairness.virtue' ,'loyalty.virtue', 'authority.virtue' ,'sanctity.virtue' ,'care.vice' ,'fairness.vice' ,'loyalty.vice' ,'authority.vice', 'sanctity.vice','moral_nonmoral_ratio', 'shares','word']]\n",
    "df.to_csv('mfd2_docs4rw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
