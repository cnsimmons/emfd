{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Document Scoring, Application, and External Validation of e-MFD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we examine the performance of the e-MFD when scoring news documents. Specifically, we contrast moral signal extracted by the e-MFD with signal extracted my the original MFD (o-MFD) and MFD2.0. We examine how ... and how the moral signal extracted by these dictionaries relates to topics that are present in these news articles. Finally, we examine the predictive validity of the e-MFD in comparison to previous MFDs when trying to predict social media share counts of these news documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import re, fnmatch \n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "punctuation += '’'\n",
    "for i in range(0,10):\n",
    "    punctuation += str(i)\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from multiprocessing import Pool,cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundations = ['care','fairness','loyalty','authority','sanctity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** The news articles used in this notebook reflect a hold-out set that was not used to construct the e-MFD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load News Articles\n",
    "news_text = pd.read_json('data/uncoded_news_text.json').set_index('url')\n",
    "news = pd.read_pickle('data/uncoded_news_meta.pkl').set_index('url')\n",
    "news = news.join(news_text['text'])\n",
    "themes = [c for c in news.columns if c.isupper()] \n",
    "news = news[['text','share_count']+themes]\n",
    "stopwords = set(list(nltk_stopwords) + list(ENGLISH_STOP_WORDS) + list(STOP_WORDS))\n",
    "news = news.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each news document entry contains a URL, the original article text, the Facebook share counts, and the presence or absence (binary coded) of 16 news topics derived from the Global Database of Events, Language, and Tone (GDELT; Leetaru & Schrodt, 2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>share_count</th>\n",
       "      <th>ACT_HARMTHREATEN</th>\n",
       "      <th>AFFECT</th>\n",
       "      <th>ARMEDCONFLICT</th>\n",
       "      <th>CYBER_ATTACK</th>\n",
       "      <th>EXHUMATION</th>\n",
       "      <th>EXTREMISM</th>\n",
       "      <th>FREESPEECH</th>\n",
       "      <th>JIHAD</th>\n",
       "      <th>KILL</th>\n",
       "      <th>LEGISLATION</th>\n",
       "      <th>MOVEMENT_SOCIAL</th>\n",
       "      <th>PROTEST</th>\n",
       "      <th>REBELLION</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>TERROR</th>\n",
       "      <th>WOUND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mobile.reuters.com/article/worldNews/id...</td>\n",
       "      <td>The Iraqi government's assault to retake the c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.cbsnews.com/news/north-korea-can-la...</td>\n",
       "      <td>WASHINGTON -- North Korea now has the capabili...</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.breitbart.com/national-security/201...</td>\n",
       "      <td>TEL AVIV – An Egyptian journalist wrote an op-...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.cnn.com/2016/12/07/europe/russia-re...</td>\n",
       "      <td>What was life like for Russians such as Tsar N...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.foxnews.com/politics/2016/12/05/for...</td>\n",
       "      <td>President Obama's former national security adv...</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://mobile.reuters.com/article/worldNews/id...   \n",
       "1  http://www.cbsnews.com/news/north-korea-can-la...   \n",
       "2  http://www.breitbart.com/national-security/201...   \n",
       "3  http://www.cnn.com/2016/12/07/europe/russia-re...   \n",
       "4  http://www.foxnews.com/politics/2016/12/05/for...   \n",
       "\n",
       "                                                text  share_count  \\\n",
       "0  The Iraqi government's assault to retake the c...          0.0   \n",
       "1  WASHINGTON -- North Korea now has the capabili...        262.0   \n",
       "2  TEL AVIV – An Egyptian journalist wrote an op-...         41.0   \n",
       "3  What was life like for Russians such as Tsar N...        114.0   \n",
       "4  President Obama's former national security adv...        244.0   \n",
       "\n",
       "   ACT_HARMTHREATEN  AFFECT  ARMEDCONFLICT  CYBER_ATTACK  EXHUMATION  \\\n",
       "0                 0       1              1             0           0   \n",
       "1                 0       0              0             0           0   \n",
       "2                 0       0              1             0           0   \n",
       "3                 0       0              0             0           0   \n",
       "4                 0       0              1             0           0   \n",
       "\n",
       "   EXTREMISM  FREESPEECH  JIHAD  KILL  LEGISLATION  MOVEMENT_SOCIAL  PROTEST  \\\n",
       "0          0           0      0     0            0                0        0   \n",
       "1          0           0      0     0            0                0        1   \n",
       "2          1           0      0     1            0                0        0   \n",
       "3          0           0      0     1            0                0        0   \n",
       "4          0           0      0     0            1                0        1   \n",
       "\n",
       "   REBELLION  RELIGION  TERROR  WOUND  \n",
       "0          0         0       1      1  \n",
       "1          0         0       0      0  \n",
       "2          0         0       0      0  \n",
       "3          0         0       0      0  \n",
       "4          1         0       0      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Score Documents with E-MFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score E-MFD\n",
    "emfd = pd.read_pickle('dictionaries/emfd_scoring.pkl')\n",
    "probabilites = [c for c in emfd.columns if c.endswith('_p')]\n",
    "senti = [c for c in emfd.columns if c.endswith('_sent')]\n",
    "\n",
    "emfd = emfd.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    \n",
    "    '''Simple function to multiprocess functions on dataframe.\n",
    "    Administers n-1 available cores to the task. '''\n",
    "    \n",
    "    df_split = np.array_split(df, cpu_count()-1)\n",
    "    pool = Pool(cpu_count()-1)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_sent(sentence):\n",
    "    \n",
    "    '''Function to preprocess sentences'''\n",
    "    \n",
    "    sentence = sentence.split(' ')\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "    sentence = [x.replace(\"'s\",'') for x in sentence]\n",
    "    for punc in punctuation:\n",
    "        sentence = [x.replace(punc,'') for x in sentence]\n",
    "    sentence = [x for x in sentence if x not in stopwords]\n",
    "    sentence = [x for x in sentence if x not in punctuation]\n",
    "    sentence = [x for x in sentence if len(x) > 2]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def score_emfd(docs):\n",
    "\n",
    "    scored_docs = []\n",
    "\n",
    "    for i, row in docs.iterrows():  \n",
    "        doc_id = i\n",
    "\n",
    "        # Turn document into spaCy DOC object\n",
    "        doc = nlp(row.text)\n",
    "\n",
    "        # Create list to store individual sentence scores\n",
    "        sentence_scores = []\n",
    "\n",
    "        # Initialize a variable to store the number of detected moral words \n",
    "        emfd_wordcount = 0 \n",
    "        non_moral_count = 0\n",
    "\n",
    "        # Start to loop over each sentence in a document\n",
    "        for s, sentence in enumerate(doc.sents):\n",
    "\n",
    "            # Run VADER to get sentence sentiment\n",
    "            sentiment = analyzer.polarity_scores(str(sentence))\n",
    "\n",
    "            # Preprocess sentence and turn into list of tokens \n",
    "            tokens = preproc_sent(str(sentence).strip())\n",
    "\n",
    "            # If an empty sentence is returned, skip this sentence\n",
    "            if len(tokens) == 0:\n",
    "                continue\n",
    "\n",
    "            # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "            emfd_score = pd.DataFrame(columns=foundations, index=range(0, len(tokens)))\n",
    "            emfd_score['pos'] = sentiment['pos']\n",
    "            emfd_score['neg'] = sentiment['neg']\n",
    "            emfd_score['neu'] = sentiment['neu']\n",
    "            emfd_score['pol'] = sentiment['compound']\n",
    "            emfd_score['word'] = ''\n",
    "\n",
    "            # Initiate scoring by looping over each token in the sentence\n",
    "            for x, token in enumerate(tokens):\n",
    "\n",
    "                # Is token in E-MFD?\n",
    "                if token in emfd.keys():\n",
    "                    # Yes: increase wordcount by 1\n",
    "                    emfd_wordcount += 1\n",
    "                    # In scoring matrix, insert words and insert weights \n",
    "                    emfd_score.at[x, 'word'] = token\n",
    "                    emfd_score.at[x,'care'] = emfd[token]['care']\n",
    "                    emfd_score.at[x,'fairness'] = emfd[token]['fairness']\n",
    "                    emfd_score.at[x,'loyalty'] = emfd[token]['loyalty']\n",
    "                    emfd_score.at[x,'authority'] = emfd[token]['authority']\n",
    "                    emfd_score.at[x,'sanctity'] = emfd[token]['sanctity']\n",
    "                else:\n",
    "                    non_moral_count += 1\n",
    "                    \n",
    "            emfd_score['word_ix'] = emfd_score.index\n",
    "            emfd_score['sentence_ix'] = int(s)\n",
    "            emfd_score['document_ix'] = int(i)\n",
    "            emfd_score['shares'] = row['share_count']\n",
    "            sentence_scores.append(emfd_score)\n",
    "\n",
    "        # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "        sentences = pd.concat(sentence_scores)\n",
    "        sentences['moral_nonmoral_ratio'] = emfd_wordcount / non_moral_count\n",
    "        scored_docs.append(sentences)\n",
    "    \n",
    "    df = pd.concat(scored_docs)\n",
    "    df = df.dropna(how='any')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_docs = parallelize_dataframe(news, score_emfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care','fairness','loyalty','authority','sanctity','moral_nonmoral_ratio','pos','neg','neu','pol','shares','word']]\n",
    "df.to_csv('emfd_docs4rw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364748"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scored_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care</th>\n",
       "      <th>fairness</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>authority</th>\n",
       "      <th>sanctity</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pol</th>\n",
       "      <th>word</th>\n",
       "      <th>word_ix</th>\n",
       "      <th>sentence_ix</th>\n",
       "      <th>document_ix</th>\n",
       "      <th>shares</th>\n",
       "      <th>moral_nonmoral_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.193301</td>\n",
       "      <td>0.173234</td>\n",
       "      <td>0.240028</td>\n",
       "      <td>0.122213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.15942</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>assault</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>retake</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122876</td>\n",
       "      <td>0.0774818</td>\n",
       "      <td>0.120347</td>\n",
       "      <td>0.142259</td>\n",
       "      <td>0.0789866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>city</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.199052</td>\n",
       "      <td>0.182222</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.19883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>civilians</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       care   fairness   loyalty authority   sanctity  pos    neg    neu  \\\n",
       "1  0.148649   0.193301  0.173234  0.240028   0.122213  0.0  0.203  0.797   \n",
       "2       0.4   0.202247  0.220779   0.15942   0.216867  0.0  0.203  0.797   \n",
       "3     0.125          0  0.206897     0.375   0.133333  0.0  0.203  0.797   \n",
       "4  0.122876  0.0774818  0.120347  0.142259  0.0789866  0.0  0.203  0.797   \n",
       "8  0.373134   0.199052  0.182222  0.173077    0.19883  0.0  0.203  0.797   \n",
       "\n",
       "      pol        word  word_ix  sentence_ix  document_ix  shares  \\\n",
       "1 -0.8555  government        1            0            0     0.0   \n",
       "2 -0.8555     assault        2            0            0     0.0   \n",
       "3 -0.8555      retake        3            0            0     0.0   \n",
       "4 -0.8555        city        4            0            0     0.0   \n",
       "8 -0.8555   civilians        8            0            0     0.0   \n",
       "\n",
       "   moral_nonmoral_ratio  \n",
       "1              1.125984  \n",
       "2              1.125984  \n",
       "3              1.125984  \n",
       "4              1.125984  \n",
       "8              1.125984  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Score Documents with MFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate MFD\n",
    "MFD = 'dictionaries/mft_original.dic'\n",
    "nummap = dict()\n",
    "mfd = dict()\n",
    "mfd_regex = dict()\n",
    "wordmode = True\n",
    "with open(MFD, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                mfd[ent[0]] = [nummap[e] for e in ent[1:]]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "# convert vocab to compiled regex for comparison\n",
    "for v in mfd.keys():\n",
    "    mfd_regex[v] = re.compile(fnmatch.translate(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate MFD2.0 \n",
    "MFD2 = 'dictionaries/mfd2.0.dic'\n",
    "nummap = dict()\n",
    "mfd2 = dict()\n",
    "wordmode = True\n",
    "with open(MFD2, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        ent = line.strip().split()\n",
    "        if line[0] == '%':\n",
    "            wordmode = not wordmode\n",
    "        elif len(ent) > 0:\n",
    "            if wordmode:\n",
    "                wordkey = ''.join([e for e in ent if e not in nummap.keys()])\n",
    "                mfd2[wordkey] = [nummap[e] for e in ent if e in nummap.keys()]\n",
    "            else:\n",
    "                nummap[ent[0]] = ent[1]\n",
    "\n",
    "mfd2 = pd.DataFrame.from_dict(mfd2).T\n",
    "mfd2['foundation'] = mfd2[0]\n",
    "del mfd2[0]\n",
    "mfd2 = mfd2.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtues = [f+'.virtue' for f in foundations]\n",
    "vices = [f+'.vice' for f in foundations]\n",
    "mfd_foundations = virtues+vices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score MFD \n",
    "docs_rw = []\n",
    "\n",
    "for i, row in news.iterrows():  \n",
    "    doc_id = i\n",
    "    \n",
    "    # Turn document into spaCy DOC object\n",
    "    doc = nlp(row.text)\n",
    "    \n",
    "    # Create list to store individual sentence scores\n",
    "    sentence_scores = []\n",
    "    \n",
    "    # Initialize a variable to store the number of detected moral words \n",
    "    mfd_wordcount = 0 \n",
    "    non_mfd_count = 0\n",
    "    \n",
    "    # Start to loop over each sentence in a document\n",
    "    for s, sentence in enumerate(doc.sents):\n",
    "        \n",
    "        # Run VADER to get sentence sentiment\n",
    "        sentiment = analyzer.polarity_scores(str(sentence))\n",
    "        \n",
    "        # Preprocess sentence and turn into list of tokens \n",
    "        tokens = preproc_sent(str(sentence).strip())\n",
    "        \n",
    "        # If an empty sentence is returned, skip this sentence\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "        #print(tokens)\n",
    "        mfd_score = pd.DataFrame(columns=mfd_foundations, index=range(0, len(tokens)))\n",
    "        mfd_score['word'] = ''\n",
    "        mfd_score = mfd_score.fillna(0)\n",
    "                \n",
    "        # Initiate scoring by looping over each token in the sentence\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in MFD?\n",
    "            for v in mfd_regex.keys():\n",
    "                if mfd_regex[v].match(token):\n",
    "                    mfd_wordcount += 1\n",
    "                    for f in mfd[v]:\n",
    "                        if f == 'moral':\n",
    "                            continue\n",
    "                        else:\n",
    "                            #print(token,f)\n",
    "                            mfd_score.at[x,'word'] = token\n",
    "                            mfd_score.at[x,f] = 1\n",
    "                else:\n",
    "                    non_mfd_count += 1\n",
    "                    mfd_score.at[x,'word'] = token\n",
    "                    continue\n",
    "        \n",
    "        mfd_score['word_ix'] = mfd_score.index\n",
    "        mfd_score['sentence_ix'] = int(s)\n",
    "        mfd_score['document_ix'] = int(i)\n",
    "        mfd_score['shares'] = row['share_count']\n",
    "        sentence_scores.append(mfd_score)\n",
    "        \n",
    "    # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "    sentences = pd.concat(sentence_scores)\n",
    "    sentences['moral_nonmoral_ratio'] = mfd_wordcount / non_mfd_count\n",
    "    #print(\"this is a document\")\n",
    "    #print(sentences)\n",
    "    docs_rw.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save scored MFD counts\n",
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care.virtue', 'fairness.virtue' ,'loyalty.virtue', 'authority.virtue' ,'sanctity.virtue' ,'care.vice' ,'fairness.vice' ,'loyalty.vice' ,'authority.vice', 'sanctity.vice', 'moral_nonmoral_ratio','shares','word']]\n",
    "df.to_csv('mfd_docs4rw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score MFD2.0 \n",
    "docs_rw = []\n",
    "\n",
    "for i, row in news.iterrows():  \n",
    "    doc_id = i\n",
    "    \n",
    "    # Turn document into spaCy DOC object\n",
    "    doc = nlp(row.text)\n",
    "    \n",
    "    # Create list to store individual sentence scores\n",
    "    sentence_scores = []\n",
    "    \n",
    "    # Initialize a variable to store the number of detected moral words \n",
    "    mfd_wordcount = 0 \n",
    "    non_mfd_count = 0\n",
    "    \n",
    "    # Start to loop over each sentence in a document\n",
    "    for s, sentence in enumerate(doc.sents):\n",
    "        \n",
    "        # Run VADER to get sentence sentiment\n",
    "        sentiment = analyzer.polarity_scores(str(sentence))\n",
    "        \n",
    "        # Preprocess sentence and turn into list of tokens \n",
    "        tokens = preproc_sent(str(sentence).strip())\n",
    "        \n",
    "        # If an empty sentence is returned, skip this sentence\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Initialize a matrix that has the 5 foundations + 3 sentiment categories as keys and that will store the scores for each detected word \n",
    "        #print(tokens)\n",
    "        mfd_score = pd.DataFrame(columns=mfd_foundations, index=range(0, len(tokens)))\n",
    "        mfd_score['word'] = ''\n",
    "        mfd_score = mfd_score.fillna(0)\n",
    "                \n",
    "        # Initiate scoring by looping over each token in the sentence\n",
    "        for x, token in enumerate(tokens):\n",
    "            \n",
    "            # Is token in MFD2?\n",
    "            if token in mfd2.keys(): \n",
    "                mfd_wordcount += 1\n",
    "                mfd_score.at[x,'word'] = token\n",
    "                mfd_score.at[x, mfd2[token]['foundation']] = 1\n",
    "                               \n",
    "            else:\n",
    "                non_mfd_count += 1\n",
    "                mfd_score.at[x,'word'] = token\n",
    "                continue\n",
    "        \n",
    "        mfd_score['word_ix'] = mfd_score.index\n",
    "        mfd_score['sentence_ix'] = int(s)\n",
    "        mfd_score['document_ix'] = int(i)\n",
    "        mfd_score['shares'] = row['share_count']\n",
    "        sentence_scores.append(mfd_score)\n",
    "        \n",
    "    # Concat all sentences and add document-level ratio of moral to non-moral words\n",
    "    sentences = pd.concat(sentence_scores)\n",
    "    sentences['moral_nonmoral_ratio'] = mfd_wordcount / non_mfd_count\n",
    "    #print(\"this is a document\")\n",
    "    #print(sentences)\n",
    "    docs_rw.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save scored MFD counts\n",
    "# Save scored documents\n",
    "df = pd.concat(docs_rw)\n",
    "df = df[['document_ix','sentence_ix','word_ix','care.virtue', 'fairness.virtue' ,'loyalty.virtue', 'authority.virtue' ,'sanctity.virtue' ,'care.vice' ,'fairness.vice' ,'loyalty.vice' ,'authority.vice', 'sanctity.vice','moral_nonmoral_ratio', 'shares','word']]\n",
    "df.to_csv('mfd2_docs4rw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
